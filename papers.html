<!DOCTYPE html>
<html>
<title>Underrated papers</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<body class="w3-content" style="max-width:1300px">

  <div class="w3-row">
    <div class="w3-third w3-white w3-container w3-center" style="height:550px">
      <div class="w3-padding-48">
        <h1 style="font-family: 'Cutive Mono', monospace;">Underrated papers</h1>
      </div>
      <div class="w3-padding-2">
        <a style="font-family: 'Cutive Mono', monospace; text-decoration: none" href="index.html">&nbsp; Home</a>
      </div>
    </div>
    <div class="w3-twothird w3-white w3-container">
      <div class="w3-padding-64 w3-center">
        <div class="w3-left-align w3-padding-small">
          <p style="font-family: 'Cutive Mono', monospace; margin-top: 0%; margin-right: 80px">
             Collecting some work here that I think is not as well known as it should be (as of 11/17/24) in either academia, government, or the AI safety community. I plan to keep this list ~up-to-date.
          </p>

          <p style="font-family: 'Cutive Mono', monospace; margin-right: 80px">
            <span style="background-color: #fff3b0; font-size: large;">
              <b>Science of DL</b>
            </span>
          </p>
          <table style="width:100%">
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2308.09543" style="color:#191970">Latent State Models of Training Dynamics</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2404.11534" style="color:#191970">Decomposing and Editing Predictions by Modeling Model Computation</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2305.12827" style="color:#191970">Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2102.13042" style="color:#191970">Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling</a></td>
            </tr>
          </table>

          <p style="font-family: 'Cutive Mono', monospace; margin-right: 80px">
            <span style="background-color: #fff3b0; font-size: large;">
              <b>Scaling Laws and Compute</b>
            </span>
          </p>
          <table style="width:100%">
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2303.13506" style="color:#191970">The Quantization Model of Neural Scaling</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2405.10938" style="color:#191970">Observational Scaling Laws and the Predictability of Language Model Performance</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2401.00448" style="color:#191970">Beyond Chinchilla-Optimal: Accounting for Inference in Language Model Scaling Laws</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://epoch.ai/blog/optimally-allocating-compute-between-inference-and-training" style="color:#191970">Optimally Allocating Compute Between Inference and Training</a></td>
            </tr>
          </table>

          <p style="font-family: 'Cutive Mono', monospace; margin-right: 80px">
            <span style="background-color: #fff3b0; font-size: large;">
              <b>Misc. Safety/Elicitation</b>
            </span>
          </p>
          <table style="width:100%">
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2406.14595" style="color:#191970">Adversaries Can Misuse Combinations of Safe Models</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2405.19550" style="color:#191970">Stress-Testing Capability Elicitation With Password-Locked Models</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2312.01037" style="color:#191970">Eliciting Latent Knowledge from Quirky Language Models</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://transluce.org/automated-elicitation" style="color:#191970">Eliciting Language Model Behaviors with Investigator Agents</a></td>
            </tr>
          </table>

          <p style="font-family: 'Cutive Mono', monospace; margin-right: 80px">
            <span style="background-color: #fff3b0; font-size: large;">
              <b>Security/Control</b>
            </span>
          </p>
          <table style="width:100%">
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://www.rand.org/pubs/research_reports/RRA2849-1.html" style="color:#191970">Securing AI Model Weights</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://www.alignmentforum.org/posts/rf66R4YsrCHgWx9RG/preventing-model-exfiltration-with-upload-limits" style="color:#191970">Preventing Model Exfiltration with Upload Limits</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2408.08926" style="color:#191970">Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://redwoodresearch.substack.com/p/a-basic-systems-architecture-for" style="color:#191970">A basic systems architecture for AI agents that do autonomous research</a></td>
            </tr>
          </table>

          <p style="font-family: 'Cutive Mono', monospace; margin-right: 80px">
            <span style="background-color: #fff3b0; font-size: large;">
              <b>Evals</b>
            </span>
          </p>
          <table style="width:100%">
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2409.16125" style="color:#191970">Analyzing Probabilistic Methods for Evaluating Agent Capabilities</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://arxiv.org/abs/2212.10561" style="color:#191970">Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://openreview.net/forum?id=3so6NRQZfG" style="color:#191970">Consistency Checks for Language Model Forecasters</a></td>
            </tr>
            <tr>
              <td style="text-align:left; font-size:0.95em"><a href="https://openreview.net/forum?id=XSeN6xZtZ9" style="color:#191970">Large Language Model Benchmarks Do Not Test Reliability</a></td>
            </tr>
          </table>
        </div>
      </div>
    </div>
  </div>
</body>
</html>
