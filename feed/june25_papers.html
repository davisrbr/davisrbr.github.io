<!DOCTYPE html>
<html>
<title>Paper Feed</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600&family=Lora:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
  :root {
    --primary-color: #191970;
    --accent-color: #4169e1;
    --highlight-color: #fff3b0;
    --light-bg: #f9f9f9;
    --border-color: #e0e0e0;
  }
  
  body {
    font-family: 'Lora', serif;
    line-height: 1.6;
    color: #222;
    font-size: 16px;
    font-weight: 400;
  }
  
  .mono-font { font-family: 'IBM Plex Mono', monospace; font-weight: 400; }
  
  a       { color: var(--accent-color); transition: color .3s, text-decoration .3s; text-decoration: none; }
  a:hover { color: var(--primary-color); text-decoration: none; }
  
  .sidebar {
    background-color: var(--light-bg);
    box-shadow: 0 0 10px rgba(0,0,0,.03);
    border-right: 1px solid var(--border-color);
  }
  
  .highlight {
    background-color: var(--highlight-color);
    padding: .2rem .5rem;
    border-radius: 2px;
    font-weight: 700;
    font-size: 1.25rem;
  }
  
  .nav-links a       { display:block; padding:8px 0; transition:transform .2s; }
  .nav-links a:hover { transform:translateX(5px); }
  .nav-links a.active{ font-weight:700; color:var(--primary-color); }
  
  .paper-item { margin-bottom:0; padding-bottom:0; }
  
  .description-toggle {
    color:var(--accent-color); cursor:pointer; font-size:.95rem; font-weight:500;
    opacity:.9; margin-top:5px; display:inline-block; transition:color .3s;
  }
  .description-toggle:hover { color:var(--primary-color); text-decoration:none; }
  
  .paper-description {
    font-size:.95rem; margin-top:5px; overflow:hidden; max-height:0; opacity:0;
    transition:max-height .3s ease-out, opacity .3s, padding .3s;
    background:rgba(240,240,240,.3); border-radius:3px;
    padding-left:5px; padding-right:5px; line-height:1.4;
  }
  .paper-description.visible { max-height:800px; opacity:1; padding:10px; }
  
  .versions-container { margin-top:15px; margin-bottom:10px; }
  
  /* Desktop */
  @media screen and (min-width:793px){
    .sidebar       { position:sticky; top:0; height:100vh; overflow-y:auto; flex:0 0 20%; width:20%; }
    .w3-twothird   { flex:0 0 80%; width:80%; }
  }
  /* Mobile */
  @media screen and (max-width:792px){
    .sidebar{ position:static; height:auto; width:100%; overflow:visible; padding-bottom:1.5rem; }
  }
</style>

<body class="w3-content" style="max-width:2500px">

  <div class="w3-row">
    <div class="w3-third sidebar w3-container w3-center">
      <div class="w3-padding-24"><h4 class="mono-font">Paper Feed</h4></div>

      <div class="versions-container">
        <div class="mono-font" style="font-size:1.15rem;">Versions</div>
        <div class="nav-links versions-nav-links">
          <!-- Navigation will be populated by JavaScript -->
        </div>
      </div>

      <div style="margin-top:30px;"></div>
      <div class="nav-links"><a href="../index.html" class="mono-font">Home</a></div>
    </div>

    <div class="w3-twothird w3-white w3-container">
      <div class="w3-padding-64 w3-center">
        <div class="w3-left-align w3-padding-small">
          <h3 class="mono-font">Paper Feed: June 2025</h3>

          <div class="intro-note mono-font" style="margin-top:1rem;margin-right:80px;background:var(--light-bg);padding:.7rem;border-radius:4px;border-left:3px solid var(--accent-color);">
            <p style="margin:0 0 .5rem 0;font-size:1rem;">
              Highlighting research I find interesting and think may deserve more attention (as of 06/03/25) from academia, government, or the AI safety community. 
            </p>
          </div>

          <!-- =====================  EVALS  ===================== -->
          <p class="mono-font" style="margin-right:80px"><span class="highlight">Evals</span></p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://arxiv.org/abs/2505.15216" target="_blank" style="color:#191970">
                BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems
              </a><br/>
              <span style="font-size:.9em;color:#666;">Andy K. Zhang, Joey Ji, […] Daniel E. Ho, Percy Liang (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://www.lesswrong.com/posts/Zr37dY5YPRT6s56jY/thomas-kwa-s-shortform?commentId=KaaSfntGEBBgadvrF" target="_blank" style="color:#191970">
                Cross-domain time horizons
              </a><br/>
              <span style="font-size:.9em;color:#666;">Thomas Kwa (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf#page=91.73" target="_blank" style="color:#191970">
                System Card: Claude Opus 4 & Claude Sonnet 4
              </a><br/>
              <span style="font-size:.9em;color:#666;">Anthropic (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://www.ft.com/content/471b5eba-2a71-4650-a019-e8d4065b78a0" target="_blank" style="color:#191970">
                Why hasn't AI taken your job yet?
              </a><br/>
              <span style="font-size:.9em;color:#666;">John Burn-Murdoch (2025)</span>
              <br/>
              <div class="description-toggle" data-target="descFTMessiness">
                Why this is notable
              </div>
              <div id="descFTMessiness" class="paper-description">
                <div class="description-content">
                  <div style="margin-bottom: 1rem;">
                    The general trends-- but not the offsets-- between messy/not messy tasks are roughly similar (plot below, created from Figure 9 in <a href="https://arxiv.org/abs/2503.14499" target="_blank">METR paper</a>). 'Messy' tasks are tasks more like those found in the real world, as measured by some features (e.g., "from a real life source" or "potential for irreversable mistasks") designed to have real-world relevance. This is a nice framing. However, the factors (Appendix D in <a href="https://arxiv.org/abs/2503.14499" target="_blank">Measuring AI Ability to Complete Long Tasks</a>) are somewhat ad-hoc and model-centric. For example, the factors "self-modification required" or "self improvement required" are relevant things to test for but aren't really 'messy.'
                    It would be great if messiness were made more coherent and rigorous.
                  </div>
                  <img src="../assets/ft_messiness.png" alt="Evolution of AI models' task success rates, by 'messiness' of the task" style="width: 66.67%; height: auto; margin-bottom: 10px;" />
                </div>
              </div>
            </li>

            <li class="paper-item">
              <a href="https://empiricrafting.substack.com/p/claude-just-refereed-the-anthropic" target="_blank" style="color:#191970">
                Claude Just Refereed the Anthropic Economic Index. Reviewer 2 Has Thoughts
              </a><br/>
              <span style="font-size:.9em;color:#666;">Andrey Fradkin and Seth Benzell (Apr 21, 2025)</span>
              <br/>
              <div class="description-toggle" data-target="descClaudeReferee">
                Why this is notable
              </div>
              <div id="descClaudeReferee" class="paper-description">
                <div class="description-content">
                  <div style="margin-bottom: 1rem;">
                    A common complaint is that professional economists do not typically take trends in AI seriously. I've only listened to a few of the most recent episodes, but I've found this series on the economics of AI useful to understand the perspective mainstream(ish) economics.
                  </div>
                  <div style="margin-bottom: 1rem;">
                    <strong>Some relevant excerpts from this podcast:</strong>
                  </div>
                  <div style="margin-bottom: 1rem;">
                    <strong>Excerpt 1:</strong><br/>
                    This is a nice point - how do usage patterns change when they've just released a new model? Are we seeing a fundamental change in the usage patterns or mostly more of the same? Is it a slow drift or a sharp discontinuity? There are so many questions to answer with this type of data, but not necessarily economic ones.
                  </div>
                  <div style="margin-bottom: 1rem;">
                    <strong>Excerpt 2:</strong><br/>
                    <strong>Seth:</strong> What I make of this is that the title of this paper should just be "Which Tasks Are Performed with AI," not "Which Economic Tasks." It's not clear what makes a task economic. In my opinion, a task is economic if it's either some sort of Robinson Crusoe economy where even if I'm not interacting with anyone, this is an economic behavior because I'm building a thing that I'm going to use, or what makes something economic is that I'm participating in a market with this thing and I'm going to buy it and sell it after I go through these steps.
                  </div>
                  <div style="margin-bottom: 1rem;">
                    "My video game is crashing cause I only have eight gigabytes of RAM" doesn't sound like either of those. It sounds like this guy is troubleshooting his consumption, which maybe could be thought of as the consumer taking on some of the job of customer service. The other example, "Can you make sure this blog post follows Chicago style?" - if I'm making an artistic or creative project that I'm just putting out on the internet for people, again, I'm not sure I would call that economic activity. So no problems with this paper being about measuring what activities or tasks people do with AI, but I think it's probably a breach too far to call these economic tasks.
                  </div>
                  <div style="margin-bottom: 1rem;">
                    <strong>Andrey:</strong> I think I agree with you. There needs to be more metadata around these conversations. A survey of whether users are using this for their job or not could be really informative, or even just a subset analysis of just the pro users who are more likely to be using this for their job.
                  </div>
                  <div>
                    I do think it's an interesting phenomenon of substituting professional labor with personal labor. Hal Varian used to bring up this example all the time with YouTube - before, you'd hire someone to repair your appliance or do work around the house, but now you can watch a YouTube video and do it yourself. This means YouTube is generating tremendous economic value that's not being measured. I think both of us are generally on board with that idea - GDP is going to miss a bunch of interesting activity just by virtue of how it's measured. But especially for an academic contribution, we want a more rigorous analysis.
                  </div>
                </div>
              </div>
            </li>
          </ul>  

          <!-- =====================  SCIENCE / INTERP  ===================== -->
          <p class="mono-font" style="margin-right:80px"><span class="highlight">Science of DL / Interpretability</span></p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://www.proquest.com/docview/3192012793?sourcetype=Dissertations%20&%20Theses" target="_blank" style="color:#191970">
                Beyond Gradients: Using Curvature Information for Deep Learning
              </a><br/>
              <span style="font-size:.9em;color:#666;">Juhan Bae (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2502.01481v2" target="_blank" style="color:#191970">
                Explaining Context Length Scaling and Bounds for Language Models
              </a><br/>
              <span style="font-size:.9em;color:#666;">Jingzhe Shi, Qinwei Ma, Hongyi Liu, Hang Zhao, Jeng-Neng Hwang, Serge Belongie, Lei Li (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2505.14352" target="_blank" style="color:#191970">
                Towards eliciting latent knowledge from LLMs with mechanistic interpretability
              </a><br/>
              <span style="font-size:.9em;color:#666;">Bartosz Cywiński, Emil Ryd, Senthooran Rajamanoharan, Neel Nanda (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2505.07184v1" target="_blank" style="color:#191970">
                Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs
              </a><br/>
              <span style="font-size:.9em;color:#666;">Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du (2025)</span>
            </li>
          </ul>

          <p class="mono-font" style="margin-right:80px"><span class="highlight">Technical AI Governance</span></p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://arxiv.org/abs/2501.16007" target="_blank" style="color:#191970">
                TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference
              </a><br/>
              <span style="font-size:.9em;color:#666;">Jack Min Ong, Matthew Di Ferrante, […], Johannes Hagemann (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://charlesyang.io/assets/Supercomputing_and_Weather_Forecasting.pdf"
                 target="_blank" style="color:#191970">
                The First Compute Arms Race: the Early History of Numerical Weather Prediction
              </a><br/>
              <span style="font-size:.9em;color:#666;">Charles Yang (2025)</span>
              <br/>
              <div class="description-toggle" data-target="descWeatherPrediction">
                Why this is notable
              </div>
              <div id="descWeatherPrediction" class="paper-description">
                I liked this a lot. Would be great to see the scaling trends pulled out to today.
              </div>
            </li>
          </ul>

          <p class="mono-font" style="margin-right:80px">
            <span class="highlight">Compute / Scaling / Reasoning</span>
          </p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://www.lesswrong.com/posts/qhjNejRxbMGQp4wHt/how-fast-can-algorithms-advance-capabilities-or-epoch?commentId=iBixRcJDZnvoEZC2F" target="_blank" style="color:#191970">
                Response to: How Fast Can Algorithms Advance Capabilities?
              </a><br/>
              <span style="font-size:.9em;color:#666;">Ryan Greenblatt (2025)</span>
              <br/>
              <div class="description-toggle" data-target="descResponse">
                Why this is notable
              </div>
              <div id="descResponse" class="paper-description">
                This is a response to "<a href="https://epochai.substack.com/p/how-fast-can-algorithms-advance-capabilities">How Fast Can Algorithms Advance Capabilities?</a>" by Henry Josephson (Epoch AI).
              </div>
            </li>

            <li class="paper-item">
              Which innovations actually change the exponent in the scaling power law? 
              <a href="https://x.com/_katieeverett/status/1925665335727808651" target="_blank" style="color:#191970">Thread 1</a>, 
              <a href="https://x.com/_katieeverett/status/1926722325073801612" target="_blank" style="color:#191970">Thread 2</a><br/>
              <span style="font-size:.9em;color:#666;">Katie Everett (2025)</span>
              <br/>
              <div class="description-toggle" data-target="descScalingExponent">
                Why this is notable
              </div>
              <div id="descScalingExponent" class="paper-description">
                Also see this related Beren Millidge write-up that also gives an intuition for power-law scaling arising from (something like the eigenvalues of the covariance matrix of) the training dataset. It seems spiritually true, to me: 
                <a href="https://www.beren.io/2025-03-01-The-Scaling-Laws-Are-In-Our-Stars-Not-Ourselves/" target="_blank">
                  The Scaling Laws Are In Our Stars, Not Ourselves
                </a>
              </div>
            </li>

            <li class="paper-item">
              <a href="https://lilianweng.github.io/posts/2025-05-01-thinking/"
                 target="_blank" style="color:#191970">
                Why We Think
              </a><br/>
              <span style="font-size:.9em;color:#666;">Lilian Weng (2025)</span>
              <br/>
              <div class="description-toggle" data-target="descWhyWeThink">
                Why this is notable
              </div>
              <div id="descWhyWeThink" class="paper-description">
                Log-loss is useful in CoT search because these can be seen as sampling over the posterior from a latent variable model. "The fundamental intent of test-time compute is to adaptively modify the model's output distribution at test time."
              </div>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2505.10475" target="_blank" style="color:#191970">
                Parallel Scaling Law for Language Models
              </a><br/>
              <span style="font-size:.9em;color:#666;">Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2506.00794" target="_blank" style="color:#191970">
                Predicting Empirical AI Research Outcomes with Language Models
              </a><br/>
              <span style="font-size:.9em;color:#666;">Jiaxin Wen, […], He He, Shi Feng (2025)</span>
            </li>
          </ul>

          <p class="mono-font" style="margin-right:80px"><span class="highlight">General Safety</span></p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://arxiv.org/abs/2501.16466" target="_blank" style="color:#191970">
                On the Feasibility of Using LLMs to Execute Multistage Network Attacks
              </a><br/>
              <span style="font-size:.9em;color:#666;">Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer, Vyas Sekar (2025)</span>
            </li>

            <li class="paper-item">
              <a href="https://openreview.net/forum?id=pljYMCYDWJ" target="_blank" style="color:#191970">
                Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference
              </a><br/>
              <span style="font-size:.9em;color:#666;">Anton Xue, Avishree Khare, […], Eric Wong (2024)</span>
            </li>

            <li class="paper-item">
              <a href="https://arxiv.org/abs/2505.11449" target="_blank" style="color:#191970">
                LLMs unlock new paths to monetizing exploits
              </a><br/>
              <span style="font-size:.9em;color:#666;">Nicholas Carlini, Milad Nasr, Edoardo Debenedetti, Barry Wang, Christopher A. Choquette-Choo, Daphne Ippolito, Florian Tramèr, Matthew Jagielski (2025)</span>
            </li>
          </ul>

          <!-- =====================  MISCELLANEOUS  ===================== -->
          <p class="mono-font" style="margin-right:80px">
            <span class="highlight">Miscellaneous</span>
          </p>
          <ul style="padding-left:20px;">
            <li class="paper-item">
              <a href="https://thebsdetector.substack.com/p/ai-materials-and-fraud-oh-my" target="_blank" style="color:#191970">
                AI, Materials, and Fraud, Oh My!
              </a><br/>
              <span style="font-size:.9em;color:#666;">Ben Shindel (2025)</span>
            </li>
          </ul>

        </div><!-- /w3-left-align -->
      </div><!-- /w3-padding-64 -->
    </div><!-- /w3-twothird -->
  </div><!-- /w3-row -->

  <script src="shared-nav.js"></script>
  <script>
    // Initialize navigation for this page
    initializeNavigation('june25');
    
    // Toggle descriptions functionality
    document.querySelectorAll('.description-toggle').forEach(t => {
      t.addEventListener('click', function(){
        const id   = this.getAttribute('data-target');
        const desc = document.getElementById(id);
        desc.classList.toggle('visible');
        this.textContent = desc.classList.contains('visible') ? 'Hide details'
                                                              : 'Why this is notable';
      });
    });
  </script>
</body>
</html> 