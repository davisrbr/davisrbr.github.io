<!DOCTYPE html>
<html>
  <head>
    <title>Davis Brown</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600&family=Lora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/components.css">
    <link rel="stylesheet" href="css/papers.css">
    <link rel="stylesheet" href="css/responsive.css">
  </head>
  <body class="w3-content" style="max-width:2500px">
    <!-- First Grid: Sidebar & Main Content -->
    <div class="w3-row">
      <!-- Sidebar with Profile -->
      <div class="w3-third sidebar w3-container w3-center">
        <div class="w3-padding-64">
          <h1 class="mono-font" style="font-size: 2rem;">Davis Brown</h1>
          <img src="assets/Brown_Davis-2-small.jpg" class="profile-img w3-margin w3-square" alt="Davis Brown" style="width:75%">
          
          <div class="social-links w3-padding-16">
            <a href="https://twitter.com/davisbrownr" target="_blank" title="Twitter">
              <i class="fab fa-twitter"></i> <span class="mono-font" style="font-size: 0.9rem;">Twitter</span>
            </a>
            <a href="https://scholar.google.com/citations?hl=en&user=zQEbpYYAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" title="Google Scholar">
              <i class="fas fa-graduation-cap"></i> <span class="mono-font" style="font-size: 0.9rem;">Scholar</span>
            </a>
          </div>
        </div>
      </div>
      
      <!-- Main Content Area -->
      <div class="w3-twothird w3-container main-content">
        <!-- Bio Section -->
        <div class="bio">
          <p class="mono-font"> 
            I am a first-year PhD student at the University of Pennsylvania advised by 
            <a href="https://riceric22.github.io/" target="_blank">Eric Wong</a> and 
            <a href="https://www.seas.upenn.edu/~hassani/" target="_blank">Hamed Hassani</a>, with research interests in AI safety, security, and the science of deep learning. 
            I'm also a research scientist in the National Security Directorate at 
            <a href="https://www.pnnl.gov/" target="_blank">Pacific Northwest National Lab</a>. Previously, I worked with a couple startups / majored in physics at UNC as a Morehead-Cain scholar.
          </p>
          
          <p class="mono-font">I've most recently been thinking about a) evals and b) AI security. See below for my current working papers, and please do reach out if you'd like to chat.</p>
          
          <p class="mono-font highlight-box">
            <a href="feed/june25_papers.html" target="_blank" class="paper-feed-link">
              <i class="fas fa-book-open" style="font-size: 0.9rem; color: var(--accent-color); margin-right: 4px;"></i>
              My paper feed of under-appreciated research (most recent: June 2025).</a> 
          </p>
          
          <!-- <p class="mono-font">
            In my free time, I like to run, ski, and 
            <a href="https://www.goodreads.com/user/show/98635701-davis-brown" target="_blank">(re-)read</a> Robert Caro's biographies.
          </p> -->
        </div>
        
        <!-- Recent Papers Section -->
        <div class="section-title">
          <span class="highlight mono-font" style="font-size: 1.25rem;">Recent Papers</span>
        </div>
        
        <div class="paper-list">
          <!-- Paper 1 -->
          <div class="paper-item w3-row">
            <div class="w3-col" style="width:70px">
              <div class="paper-year">2025</div>
            </div>
            <div class="w3-rest paper-content">
              <a href="https://arxiv.org/abs/2503.01986" class="paper-title" target="_blank">
                Adaptively profiling models with task elicitation
              </a>
              <div class="paper-authors">
                <b>Davis Brown</b>, Prithvi Balehannina, Helen Jin, Shreya Havaldar, Hamed Hassani, Eric Wong
              </div>
              <div class="description-toggle" data-target="desc1">
                Paper Description
              </div>
              <div id="desc1" class="paper-description">
                <div class="description-content">
                  <img src="assets/cluster_visualization_attempt_super_tiny.jpeg" alt="Task elicitation visualization" />
                  <div>
                      Language models have a 'jagged frontier' of capabilities and behaviors, performing exceptionally well on some tasks and brittle on others. We map this frontier by adaptively probing the model under evaluation with new tasks. We term this procedure as <i>task elicitation</i>, and generate new hard tasks in truthfulness, forecasting, social harms, and more. 
                  </div>
                </div>
              </div>
            </div>
          </div>
          
          <!-- Paper 2 -->
          <div class="paper-item w3-row">
            <div class="w3-col" style="width:70px">
              <div class="paper-year">ICML '25 (spotlight)</div>
            </div>
            <div class="w3-rest paper-content">
              <a href="https://arxiv.org/abs/2503.06366" class="paper-title" target="_blank">
                A Suite of Datasets Capturing Research-level Conjecturing Ability in Pure Mathematics
              </a>
              <div class="paper-authors">
                {Herman Chau, Helen Jenne, <b>Davis Brown</b>}, Jesse He, Mark Raugas, Sara C. Billey, Henry Kvinge
              </div>
              <div class="description-toggle" data-target="desc2">
                Paper Description
              </div>
              <div id="desc2" class="paper-description">
                <div class="description-content">
                  <img src="assets/algcom_smaller2.jpg" alt="Semistandard Young tableaux" style="width: 45%; height: auto;" />
                  <div>
                      We build datasets and tasks desgined to evaluate a model's ability to generate new research-level algebraic combinatorics conjectures. Many of the problems we select are currently open and pose strong challenges to both frontier models and mathematicians using models-as-tools. For each problem, we provide a large amount of associated data and train narrow models to both serve as baselines / objects of study for interpretability.
                  </div>
                </div>

              </div>
            </div>
          </div>
          
          <!-- Paper 3 -->
          <div class="paper-item w3-row">
            <div class="w3-col" style="width:70px">
              <div class="paper-year">2025</div>
            </div>
            <div class="w3-rest paper-content">
              <a href="https://openreview.net/forum?id=j9IMNLGXi8" class="paper-title" target="_blank">
                How Does LLM Compression Affect Weight Exfiltration Attacks?
              </a>
              <div class="paper-authors">
                <b>Davis Brown</b>, JP Rivera, Mantas Mazeika
              </div>
              <div class="description-toggle" data-target="desc3">
                Paper Description
              </div>
              <div id="desc3" class="paper-description">
                <div class="description-content">
                  <img src="assets/exfil.png" alt="Model exfiltration diagram. Higher decompression costs enable smaller weights." />
                  <div>
                    Models can be compressed far more than standard practice suggests (e.g., 4 bits-per-parameter) if one is willing to do a bit of additional training to 'decompress' them afterwards. This increases the risk of model weight exfiltration. We find some early evidence that larger models are easier / cheaper to compress in this way.
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        
        <!-- Older Work Toggle -->
        <div class="toggle-link" id="older-work-toggle" style="margin-top: 20px; margin-bottom: 10px; font-size: 1rem;">Some older work</div>
        
        <!-- Older Work Section with Toggle -->
        <div>
          <div id="olderWork" class="older-works">
            <div class="paper-list">
              <!-- Older Paper 1 -->
              <div class="paper-item w3-row">
                <div class="w3-col" style="width:70px">
                  <div class="paper-year">EMNLP '23</div>
                </div>
                <div class="w3-rest paper-content">
                  <a href="https://arxiv.org/abs/2310.14993" class="paper-title" target="_blank">
                    Understanding the Inner Workings of Language Models Through Representation Dissimilarity
                  </a>
                  <div class="paper-authors">
                    <b>Davis Brown</b>, Charles Godfrey, Nicholas Konz, Jonathan Tu, Henry Kvinge
                  </div>
                  <div class="description-toggle" data-target="desc4">
                    Paper Description
                  </div>
                  <div id="desc4" class="paper-description">
                    We apply model-diffing methods to compare the hidden layers between different language models. We show that these measures can identify and locate generalization properties of models that are invisible if you just look at test set performance.
                  </div>
                </div>
              </div>
              
              <!-- Older Paper 2 -->
              <div class="paper-item w3-row">
                <div class="w3-col" style="width:70px">
                  <div class="paper-year">HiLD ICML '23</div>
                </div>
                <div class="w3-rest paper-content">
                  <a href="https://arxiv.org/abs/2307.12941" class="paper-title" target="_blank">
                    On Privileged and Convergent Bases in Neural Network Representations
                  </a>
                  <div class="paper-authors">
                    {<b>Davis Brown</b>, Nikhil Vyas}, Yamini Bansal
                  </div>
                  <div class="description-toggle" data-target="desc5">
                    Paper Description
                  </div>
                  <div id="desc5" class="paper-description">
                    The neuron basis of neural networks 'matters,' in that it is necessary to have one to achieve good performance. However, it does not matter that much, in that the basis is inconsistent across training runs.
                  </div>
                </div>
              </div>
              
              <!-- Older Paper 3 -->
              <div class="paper-item w3-row">
                <div class="w3-col" style="width:70px">
                  <div class="paper-year">NeurIPS '22</div>
                </div>
                <div class="w3-rest paper-content">
                  <a href="https://arxiv.org/abs/2205.14258" class="paper-title" target="_blank">
                    On the Symmetries of Deep Learning Models and their Internal Representations
                  </a>
                  <div class="paper-authors">
                    {Charles Godfrey, <b>Davis Brown</b>}, Tegan Emerson, Henry Kvinge
                  </div>
                  <div class="description-toggle" data-target="desc6">
                    Paper Description
                  </div>
                  <div id="desc6" class="paper-description">
                    We characterize how activation functions lead to certain symmetries. Then, we provide some experiments on <i>model stitching</i>, where we 'glue' together different hidden layers of models by learning permutations between their respective neurons-- this works surprisingly well.
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    
    <!-- Back to Top Button -->
    <div id="back-to-top">
      <i class="fas fa-arrow-up"></i>
    </div>

    <!-- JavaScript -->
    <script>
      // Toggle Older Work
      document.getElementById('older-work-toggle').addEventListener('click', function() {
        var elem = document.getElementById("olderWork");
        elem.classList.toggle("visible");
        
        // Change text based on current state
        if (elem.classList.contains("visible")) {
          this.textContent = "Hide older work";
        } else {
          this.textContent = "Some older work";
        }
      });
      
      // Toggle Paper Descriptions
      document.querySelectorAll('.description-toggle').forEach(toggle => {
        toggle.addEventListener('click', function() {
          const targetId = this.getAttribute('data-target');
          const descElement = document.getElementById(targetId);
          
          descElement.classList.toggle('visible');
          
          // Update toggle text
          if (descElement.classList.contains('visible')) {
            this.textContent = 'Hide description';
          } else {
            this.textContent = 'Paper Description';
          }
        });
      });
      
      // Back to Top Button
      window.onscroll = function() {scrollFunction()};
      
      function scrollFunction() {
        if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
          document.getElementById("back-to-top").style.display = "block";
        } else {
          document.getElementById("back-to-top").style.display = "none";
        }
      }
      
      document.getElementById('back-to-top').addEventListener('click', function() {
        document.body.scrollTop = 0; // For Safari
        document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
      });
      
    </script>
  </body>
</html>
